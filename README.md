# Large Language Models for Computer-Aided Design: A Survey

This repo is constructed for collecting papers on state-of-the-art large language models as well as their applications on computer-aided design according to our survey paper-[_**Large Language Models for Computer-Aided Design: A Survey**_](https://arxiv.org/abs/2505.08137).
# Overview
![Taxonomy](taxonomy.png)

# Catalogue
## [LLMs Taxonomy](#1)
### [Closed Source LLMs](#1.1)
- [The GPT Family](#1.1.1)
- [The PaLM Family](#1.1.2)
- [The Gemini Series](#1.1.3)
### [Publicly Available LLMs](#1.2)
  - [The LLaMA Family](#1.2.1)
  - [The DeepSeek Family](#1.2.2)
### [Others](#1.3)
## [CAD Application Taxonomy](#2)
### [Data Generation](#2.1)
### [CAD Code Generation](#2.2)
### [Parametric CAD Generation](#2.3)
### [Image Generation](#2.4)
### [Model Evaluation](#2.5)
### [Text Generation](#2.6)

<p id="1"></p >

## LLMs Taxonomy
<p id="1.1"></p >

### 1. Closed Source LLMs
<p id="1.1.1"></p >

#### 1.1 The GPT Family

[Language Models are Few-Shot Learners](https://github.com/YangLing0818/Diffusion-Models-Papers-Survey-Taxonomy)

[Evaluating Large Language Models Trained on Code](https://arxiv.org/abs/2107.03374)

[WebGPT: Browser-assisted question-answering with human feedback](https://arxiv.org/abs/2112.09332)

[Training language models to follow instructions with human feedback
](https://proceedings.neurips.cc/paper_files/paper/2022/hash/b1efde53be364a73914f58805a001731-Abstract-Conference.html)

[GPT-4 Technical Report](https://arxiv.org/abs/2303.08774)

[GPT-4V(ision) System Card](https://cdn.openai.com/papers/GPTV_System_Card.pdf)

[GPT-4o System Card](https://arxiv.org/abs/2410.21276)

[OpenAI o1 System Card](https://arxiv.org/abs/2412.16720)
<p id="1.1.2"></p >

#### 1.2 The PaLM Family

[PaLM: Scaling Language Modeling with Pathways](https://www.jmlr.org/papers/v24/22-1144.html)

[PaLM 2 Technical Report](https://arxiv.org/abs/2305.10403)

[Large language models encode clinical knowledge](https://www.nature.com/articles/s41586-023-06291-2)

[Toward expert-level medical question answering with large language models](https://www.nature.com/articles/s41591-024-03423-7)

[PaLM-E: An Embodied Multimodal Language Model](https://proceedings.mlr.press/v202/driess23a.html)

[Transcending Scaling Laws with 0.1% Extra Compute](https://openreview.net/forum?id=Cf6VhQFmhP)

[Scaling Instruction-Finetuned Language Models](https://www.jmlr.org/papers/v25/23-0870.html)
<p id="1.1.3"></p >

#### 1.3 The Gemini Series
[Gemini: A Family of Highly Capable Multimodal Models](https://arxiv.org/abs/2312.11805)
[Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context](https://arxiv.org/abs/2403.05530)

[Gemma: Open Models Based on Gemini Research and Technology](https://arxiv.org/abs/2403.08295)

[Gemma 2: Improving Open Language Models at a Practical Size](https://arxiv.org/abs/2408.00118)
<p id="1.2"></p >

### 2. Publicly Available LLMs
<p id="1.2.1"></p >

#### 2.1 The LLaMA Family
[LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/abs/2302.13971)

[Llama 2: Open Foundation and Fine-Tuned Chat Models](https://arxiv.org/abs/2307.09288)

[The Llama 3 Herd of Models](https://arxiv.org/abs/2407.21783)
<p id="1.2.2"></p >

#### 2.2 The DeepSeek Family
[DeepSeek-Coder: When the Large Language Model Meets Programming -- The Rise of Code Intelligence](https://arxiv.org/abs/2401.14196)

[DeepSeek LLM: Scaling Open-Source Language Models with Longtermism](https://arxiv.org/abs/2401.02954)

[DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models](https://openreview.net/forum?id=EmUsC2FogT)

[DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models](https://arxiv.org/abs/2402.03300)

[DeepSeek-VL: Towards Real-World Vision-Language Understanding](https://arxiv.org/abs/2403.05525)

[DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model](https://arxiv.org/abs/2405.04434)

[DeepSeek-V3 Technical Report](https://arxiv.org/abs/2412.19437)

[DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning](https://arxiv.org/abs/2501.12948)
<p id="1.3"></p >

### 3. Others

[PanGu-Σ: Towards Trillion Parameter Language Model with Sparse Heterogeneous Computing](https://arxiv.org/abs/2303.10845)

[BloombergGPT: A Large Language Model for Finance](https://arxiv.org/abs/2303.17564)

[The Claude 3 Model Family: Opus, Sonnet, Haiku](https://www-cdn.anthropic.com/de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/Model_Card_Claude_3.pdf)

-------------------------------------------------------------------------

[LIMA: Less Is More for Alignment](https://proceedings.neurips.cc/paper_files/paper/2023/hash/ac662d74829e4407ce1d126477f4a03a-Abstract-Conference.html)

[Crosslingual Generalization through Multitask Finetuning](https://virtual2023.aclweb.org/paper_P283.html)

[QLoRA: Efficient Finetuning of Quantized LLMs](https://proceedings.neurips.cc/paper_files/paper/2023/hash/1feb87871436031bdc0f2beaa62a049b-Abstract-Conference.html)

[Mistral 7B](https://arxiv.org/abs/2310.06825)

[Code Llama: Open Foundation Models for Code](https://arxiv.org/abs/2308.12950)

[Gorilla: Large Language Model Connected with Massive APIs](https://proceedings.neurips.cc/paper_files/paper/2024/hash/e4c61f578ff07830f5c37378dd3ecb0d-Abstract-Conference.html)

[Giraffe: Adventures in Expanding Context Lengths in LLMs](https://arxiv.org/abs/2308.10882)

[How Far Can Camels Go? Exploring the State of Instruction Tuning on Open Resources](https://proceedings.neurips.cc/paper_files/paper/2023/hash/ec6413875e4ab08d7bc4d8e225263398-Abstract-Datasets_and_Benchmarks.html)

[Focused Transformer: Contrastive Training for Context Scaling](https://proceedings.neurips.cc/paper_files/paper/2023/hash/8511d06d5590f4bda24d42087802cc81-Abstract-Conference.html)

[Qwen Technical Report](https://arxiv.org/abs/2309.16609)

[Visual Instruction Tuning](https://proceedings.neurips.cc/paper_files/paper/2023/hash/6dcf277ea32ce3288914faf369fe6de0-Abstract-Conference.html)

[MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models](https://openreview.net/forum?id=1tZbq88f27)

[InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning](https://arxiv.org/abs/2305.06500)

[PandaGPT: One Model To Instruction-Follow Them All](https://aclanthology.org/2023.tllm-1.2/)

[ChatGLM: A Family of Large Language Models from GLM-130B to GLM-4 All Tools](https://arxiv.org/abs/2406.12793)

[Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling](https://proceedings.mlr.press/v202/biderman23a.html)

[CodeGen2: Lessons for Training LLMs on Programming and Natural Languages](https://arxiv.org/abs/2305.02309)

[StarCoder: may the source be with you!](https://openreview.net/forum?id=KoFOg41haE)

[Baichuan 2: Open Large-scale Language Models](https://arxiv.org/abs/2309.10305)

[FLM-101B: An Open LLM and How to Train It with $100K Budget](https://arxiv.org/abs/2309.03852)

[Skywork: A More Open Bilingual Foundation Model](https://arxiv.org/abs/2310.19341)

[Llemma: An Open Language Model for Mathematics](https://openreview.net/forum?id=4WnqRR915j)

[WizardLM: Empowering Large Pre-Trained Language Models to Follow Complex Instructions](https://openreview.net/forum?id=CfXh93NDgH)

[The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only](https://arxiv.org/abs/2306.01116)

[Zephyr: Direct Distillation of LM Alignment](https://openreview.net/forum?id=aKkAwZB6JV#discussion)

[Orca: Progressive Learning from Complex Explanation Traces of GPT-4](https://arxiv.org/abs/2306.02707)

[XuanYuan 2.0: A Large Chinese Financial Chat Model with Hundreds of Billions Parameters](https://dl.acm.org/doi/abs/10.1145/3583780.3615285)

[CodeT5+: Open Code Large Language Models for Code Understanding and Generation](https://aclanthology.org/2023.emnlp-main.68/)

[Jamba: A Hybrid Transformer-Mamba Language Model](https://arxiv.org/abs/2403.19887)

[Stable LM 2 1.6B Technical Report](https://arxiv.org/abs/2402.17834)

-------------------------------------------------------------------------

[InternVL: Scaling up Vision Foundation Models and Aligning for Generic Visual-Linguistic Tasks](https://openaccess.thecvf.com/content/CVPR2024/html/Chen_InternVL_Scaling_up_Vision_Foundation_Models_and_Aligning_for_Generic_CVPR_2024_paper.html)

[Mixtral of Experts](https://arxiv.org/abs/2401.04088)

[Self-Instruct: Aligning Language Models with Self-Generated Instructions](https://aclanthology.org/2023.acl-long.754/)

[CoCa: Contrastive Captioners are Image-Text Foundation Models](https://openreview.net/forum?id=Ee277P3AYC)

[Qwen2.5-Coder Technical Report](https://arxiv.org/abs/2409.12186)

[BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models](https://proceedings.mlr.press/v202/li23q)

[OpenELM: An Efficient Language Model Family with Open Training and Inference Framework](https://arxiv.org/abs/2404.14619)

[Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone](https://arxiv.org/abs/2404.14219)

[TinyLLaVA: A Framework of Small-scale Large Multimodal Models](https://arxiv.org/abs/2402.14289)

[Qwen2 Technical Report](https://arxiv.org/abs/2407.10671)

[Improved Baselines with Visual Instruction Tuning](https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Improved_Baselines_with_Visual_Instruction_Tuning_CVPR_2024_paper.html)

[LLaVA-OneVision: Easy Visual Task Transfer](https://arxiv.org/abs/2408.03326)

[Evaluating Text-to-Visual Generation withʉmage-to-Text Generation](https://link.springer.com/chapter/10.1007/978-3-031-72673-6_20)

[MiniCPM: Unveiling the Potential of Small Language Models with Scalable Training Strategies](https://openreview.net/forum?id=3X2L2TFr0f#discussion)
<p id="2"></p >

## CAD Application Taxonomy
<p id="2.1"></p >

### 1. Data Generation

[OpenECAD: An efficient visual language model for editable 3D-CAD design](https://www.sciencedirect.com/science/article/abs/pii/S0097849324001833)

[CAD-MLLM: Unifying Multimodality-Conditioned CAD Generation With MLLM](https://arxiv.org/abs/2411.04954)

[Text2CAD: Generating Sequential CAD Designs from Beginner-to-Expert Level Text Prompts](https://proceedings.neurips.cc/paper_files/paper/2024/hash/0e5b96f97c1813bb75f6c28532c2ecc7-Abstract-Conference.html)

[CAD-GPT: Synthesising CAD Construction Sequence with Spatial Reasoning-Enhanced Multimodal LLMs](https://ojs.aaai.org/index.php/AAAI/article/view/32849)

[BlenderLLM: Training Large Language Models for Computer-Aided Design with Self-improvement](https://arxiv.org/abs/2412.14203)

[CAD Translator: An Effective Drive for Text to 3D Parametric Computer-Aided Design Generative Modeling](https://dl.acm.org/doi/abs/10.1145/3664647.3681549)
<p id="2.2"></p >

### 2. CAD Code Generation
[LLM4CAD: Multi-Modal Large Language Models for 3D Computer-Aided Design Generation](https://asmedigitalcollection.asme.org/IDETC-CIE/proceedings-abstract/IDETC-CIE2024/88407/1208976)

[LLM4CAD: Multimodal Large Language Models for Three-Dimensional Computer-Aided Design Generation](https://asmedigitalcollection.asme.org/computingengineering/article-abstract/25/2/021005/1208543/LLM4CAD-Multimodal-Large-Language-Models-for-Three?redirectedFrom=fulltext)

[Large Language Models for Computer-Aided Design Fine Tuned: Dataset and Experiments](https://asmedigitalcollection.asme.org/mechanicaldesign/article-abstract/147/4/041710/1212251/Large-Language-Models-for-Computer-Aided-Design?redirectedFrom=fulltext)

[Generating CAD Code with Vision-Language Models for 3D Designs](https://openreview.net/forum?id=BLWaTeucYX)

[Query2CAD: Generating CAD models using natural language queries](https://arxiv.org/abs/2406.00144)

[How Can Large Language Models Help Humans in Design and Manufacturing?](https://arxiv.org/abs/2307.14377)

[Large Language Models for Design and Manufacturing](https://mit-genai.pubpub.org/pub/nmypmnhs/release/2)

[Utilizing ChatGPT to assist CAD design for microfluidic devices](https://pubs.rsc.org/en/content/articlelanding/2015/3a/d3lc00518f/unauth)

[CAD-Assistant: Tool-Augmented VLLMs as Generic CAD Task Solvers](https://arxiv.org/abs/2412.13810)

[CAD-Recode: Reverse Engineering CAD Code from Point Clouds](https://arxiv.org/abs/2412.14042)

[A Solver-Aided Hierarchical Language for LLM-Driven CAD Design](https://arxiv.org/abs/2502.09819)

[Artificial Intelligence and Large Language Models in CAD](http://hdl.handle.net/20.500.12380/308899)

[QueryCAD: Grounded Question Answering for CAD Models](https://arxiv.org/abs/2409.08704)

[From Idea to CAD: A Language Model-Driven Multi-Agent System for Collaborative Design](https://arxiv.org/abs/2503.04417)

[An Investigation on Utilizing Large Language Model for Industrial Computer-Aided Design Automation](https://www.sciencedirect.com/science/article/pii/S2212827124006656)
<p id="2.3"></p >

### 3. Parametric CAD Generation

[Cadvlm: Bridging language and vision in the generation of parametric cad sketches](https://link.springer.com/chapter/10.1007/978-3-031-72897-6_21)

[Img2CAD: Reverse Engineering 3D CAD Models from Images through VLM-Assisted Conditional Factorization](https://arxiv.org/abs/2408.01437)

[FlexCAD: Unified and Versatile Controllable CAD Generation with Fine-tuned Large Language Models](https://arxiv.org/abs/2411.05823)
<p id="2.4"></p >

### 4. Image Generation

[ChatCAD: An MLLM-Guided Framework for Zero-shot CAD Drawing Restoration](https://ieeexplore.ieee.org/abstract/document/10890248)
<p id="2.5"></p >

### 5. Model Evaluation

[Text-to-CAD Generation Through Infusing Visual Feedback in Large Language Models](https://arxiv.org/abs/2501.19054)
<p id="2.6"></p >

### 6. Text Generation

[3DALL-E: Integrating Text-to-Image AI in 3D Design Workflows](https://dl.acm.org/doi/abs/10.1145/3563657.3596098)

[ReparamCAD: Zero-shot CAD Re-Parameterization for Interactive Manipulation](https://dl.acm.org/doi/abs/10.1145/3610548.3618219)

[CADTalk: An Algorithm and Benchmark for Semantic Commenting of CAD Programs](https://openaccess.thecvf.com/content/CVPR2024/html/Yuan_CADTalk_An_Algorithm_and_Benchmark_for_Semantic_Commenting_of_CAD_CVPR_2024_paper.html)

[An intelligent interactive system based on LLM to combine CAD API development with FEA](https://ieeexplore.ieee.org/abstract/document/10862035)

[Leveraging Vision-Language Models for Manufacturing Feature Recognition in CAD Designs](https://arxiv.org/abs/2411.02810)

[AI large models bring great opportunities to reusable design of cad software](https://doiserbia.nb.rs/Article.aspx?id=1820-02142400046S)

[From Concept to Manufacturing: Evaluating Vision-Language Models for Engineering Design](https://arxiv.org/abs/2311.12668)

[From 2D CAD Drawings to 3D Parametric Models: A Vision-Language Approach](https://ojs.aaai.org/index.php/AAAI/article/view/32858)

[Mini-InternVL: a flexible-transfer pocket multi-modal model with 5% parameters and 90% performance](https://link.springer.com/article/10.1007/s44267-024-00067-6)

[Large Language Models for Manufacturing](https://arxiv.org/abs/2410.21418)
